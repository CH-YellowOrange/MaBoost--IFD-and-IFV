{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ========== Step 1: å…¨éƒ¨å­—æ®µ ==========\n",
    "cols = [\n",
    "    'DCN','TRANDATE','SEQNUM','PERSONID','OWNER','ROLECODE1','ROLECODE2','ROLECODE3','ROLECODE4',\n",
    "    'ADDRESS1','ADDRESS2','CITY','STATE','ZIPCODE','COUNTRY','PHONE','CNAME','CNUM',\n",
    "    'CUSIP6','CUSIP2','TICKER','SECID','SECTOR','INDUSTRY','FORMTYPE','ACQDISP','OPTIONSELL',\n",
    "    'OWNERSHIP','SHARESHELD','SHARESHELD_ADJ','SHARES','SHARES_ADJ','TPRICE','TPRICE_ADJ',\n",
    "    'TRANCODE','SECTITLE','AMEND','CLEANSE','FDATE','CDATE','MAINTDATE','SECDATE','SIGDATE',\n",
    "    'TRANDATE_AR','ACQDISP_AR','TPRICE_AR','TRANCODE_AR','gap_days','SEC_Business_Day',\n",
    "    'SEC_Business_Day_Lag2','delay','id'\n",
    "]\n",
    "\n",
    "# ========== Step 2: è®¾ç½®å­—æ®µç±»å‹ï¼ˆèŠ‚çœå†…å­˜ï¼‰ ==========\n",
    "category_cols = [\n",
    "    'ROLECODE1','ROLECODE2','ROLECODE3','ROLECODE4','ACQDISP','OPTIONSELL','OWNERSHIP',\n",
    "    'TRANCODE','SECTITLE','FORMTYPE','TICKER','STATE','COUNTRY','TRANCODE_AR','ACQDISP_AR'\n",
    "]\n",
    "date_cols = [\n",
    "    'TRANDATE','FDATE','CDATE','MAINTDATE','SECDATE','SIGDATE',\n",
    "    'TRANDATE_AR','SEC_Business_Day','SEC_Business_Day_Lag2'\n",
    "]\n",
    "numeric_cols = [\n",
    "    'SEQNUM','SHARESHELD','SHARESHELD_ADJ','SHARES','SHARES_ADJ',\n",
    "    'TPRICE','TPRICE_ADJ','gap_days','delay','SEC_Business_Day','SEC_Business_Day_Lag2'\n",
    "]\n",
    "\n",
    "dtype_dict = {col: 'category' for col in category_cols}\n",
    "dtype_dict.update({col: 'float32' for col in numeric_cols})\n",
    "dtype_dict.update({'id': 'int8'})  # æ ‡ç­¾\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Step 3: è¯»å– CSV ==========\n",
    "print(\"ğŸ“¥ æ­£åœ¨è¯»å–æ•°æ®ï¼Œè¯·ç¨å€™...\")\n",
    "#df = pd.read_csv(\"identify_delay.csv\", usecols=cols, dtype=dtype_dict, parse_dates=date_cols, low_memory=False)\n",
    "#df = pd.read_csv(\"identify_delay.csv\", usecols=cols, dtype=dtype_dict, parse_dates=date_cols, low_memory=False, encoding='ISO-8859-1')\n",
    "df = pd.read_csv(\n",
    "    \"identify_delay.csv\",\n",
    "    usecols=cols,\n",
    "    dtype=dtype_dict,  # ä¸åŒ…å«æ—¥æœŸåˆ—\n",
    "    parse_dates=date_cols,  # æŠŠè¿™äº›å­—æ®µè§£æä¸º datetime\n",
    "    encoding='ISO-8859-1',  # æˆ–ä½ åˆšæ‰å°è¯•æˆåŠŸçš„ç¼–ç \n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "print (df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Step 4: ç¼–ç ç±»åˆ«å˜é‡ ==========\n",
    "print(\"ğŸ” ç¼–ç ç±»åˆ«ç‰¹å¾...\")\n",
    "for col in category_cols:\n",
    "    df[col] = df[col].astype('str').fillna('missing')\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Step 5: æ—¶é—´ç‰¹å¾æå– ==========\n",
    "print(\"ğŸ•°ï¸ æå–æ—¶é—´ç‰¹å¾...\")\n",
    "for col in date_cols:\n",
    "    df[f\"{col}_year\"] = df[col].dt.year\n",
    "    df[f\"{col}_month\"] = df[col].dt.month\n",
    "    df[f\"{col}_day\"] = df[col].dt.day\n",
    "    df[f\"{col}_weekday\"] = df[col].dt.weekday\n",
    "    df.drop(columns=col, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Step 6: é€‰æ‹©ç‰¹å¾å’Œæ ‡ç­¾ ==========\n",
    "df = df.drop(columns=[\n",
    "    'DCN','PERSONID','OWNER','ADDRESS1','ADDRESS2','CITY','ZIPCODE','PHONE','CNAME','CNUM',\n",
    "    'CUSIP6','CUSIP2','SECID','SECTOR','INDUSTRY','AMEND','CLEANSE'\n",
    "])  # å»æ‰éç»“æ„åŒ–æˆ–IDå­—æ®µ\n",
    "\n",
    "X = df.drop(columns=['id'])\n",
    "y = df['id']\n",
    "\n",
    "# ========== Step 7: åˆ’åˆ†æ•°æ®é›† ==========\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. æ ‡ç­¾æ˜¯å¦åªæœ‰ä¸€ç§\n",
    "print(\"y_train counts:\", np.bincount(y_train))\n",
    "print(\"y_test counts:\", np.bincount(y_test))\n",
    "\n",
    "# 2. è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ˜¯å¦é‡åˆ\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Intersection:\", np.intersect1d(X_train.values, X_test.values).shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Step 8: è®­ç»ƒ XGBoost ==========\n",
    "print(\"âš™ï¸ è®­ç»ƒ XGBoost æ¨¡å‹...\")\n",
    "#model = xgb.XGBClassifier(\n",
    "#    objective='binary:logistic',\n",
    "#    eval_metric='logloss',\n",
    "#    use_label_encoder=False,\n",
    "#    tree_method='hist',\n",
    "#    max_depth=12,\n",
    "#    learning_rate=0.01,\n",
    "#    n_estimators=100,\n",
    " #   random_state=42\n",
    "#)\n",
    "\"\"\"\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    tree_method='hist',  # or 'gpu_hist' if GPU available\n",
    "    max_depth=9,\n",
    "    learning_rate=0.005,\n",
    "    n_estimators=500,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.2,\n",
    "    min_child_weight=5,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',                # æ›´é€‚åˆäºŒåˆ†ç±»\n",
    "    use_label_encoder=False,\n",
    "    tree_method='hist',              # æˆ– 'gpu_hist'ï¼ˆæ¨èï¼Œæœ‰GPUå°±ç”¨ï¼‰\n",
    "    \n",
    "    max_depth=10,                    # å¯ä»¥é€‚å½“å¤§äº›\n",
    "    min_child_weight=10,             # é¿å…è¿‡æ‹Ÿåˆ\n",
    "    gamma=0.8,                       # å‰ªæé˜ˆå€¼\n",
    "    subsample=0.8,                   # è¡Œé‡‡æ ·\n",
    "    colsample_bytree=0.8,            # ç‰¹å¾é‡‡æ ·\n",
    "\n",
    "    learning_rate=0.1,              # å­¦ä¹ ç‡é€‚ä¸­\n",
    "    n_estimators=3000,                # å¤šäº›è¿­ä»£æ¬¡æ•°é…åˆè¾ƒå°å­¦ä¹ ç‡\n",
    "\n",
    "    reg_alpha=0.1,                   # L1 æ­£åˆ™\n",
    "    reg_lambda=1.0,                  # L2 æ­£åˆ™\n",
    "\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ========== Step 9: è¯„ä¼°æ¨¡å‹ ==========\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ğŸ“Š åˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ğŸ¯ AUC åˆ†æ•°:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "# ========== Step 10: ç‰¹å¾é‡è¦æ€§ ==========\n",
    "xgb.plot_importance(model, max_num_features=20, height=0.5)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
